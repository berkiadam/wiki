
# Bevezet

TODO

# Mi az a g√©p tanul√°s

A g√©pi tanul√°s elnevez√©s egy kicsit f√©lrevezet≈ë. A koncepci√≥ l√©nyege nem az, hogy egy olyan g√©pet √©p√≠t√ºnk, ami b√°rmit meg tud tanulni, hanem hogy a modell√ºnket, amit egy bizonyos probl√©ma megold√°s√°ra hoztunk l√©tre tan√≠t√≥ adatokkal √°ll√≠tottuk be ("tan√≠tunk"), hogy el tudja v√©gezni egy el≈ëre meghat√°rozott feladatot. A modell ebben a kontextusban egy el≈ëre meghat√°rozott matematikai f√ºggv√©ny, amelynek vannak param√©terei (s√∫lyai), √©s amelyet megpr√≥b√°lunk √∫gy be√°ll√≠tani, hogy j√≥l m≈±k√∂dj√∂n egy adott feladaton. Teh√°t a modell √∂ssze√°ll√≠t√°sakor val√≥ban "tan√≠tjuk" a modellt, m√°shogy mondva, a f√ºggv√©ny param√©tereit √°ll√≠tgatjuk. Miut√°n betan√≠tottuk a modellt, ezek a param√©terek t√∂bb√© nem v√°ltoznak, innent≈ël kezdve tudunk "k√©rd√©seket" feltenni a modellnek, amire a modell a v√©gs≈ë param√©ter be√°ll√≠t√°soknak megfelel≈ëen "v√°laszt" fog adni. 

**Mi a probl√©ma a "Machine Learning" kifejez√©ssel?**
- A g√©p nem ‚Äûtanul‚Äù, csak optimaliz√°l. Nem lesz tudatos, nem tud √∫j fogalmakat alkotni, nem √©rti a vil√°got.
- A ‚Äûmachine‚Äù sz√≥ f√©lrevezet≈ë antropomorfiz√°l√°s. Ez csak matematika sz√°m√≠t√≥g√©pen futtatva.
- A ‚Äûlearning‚Äù sz√≥ emberi tanul√°st sugall, holott: nincs meg√©rt√©s, nincs sz√°nd√©k, nincs bels≈ë reprezent√°ci√≥ ‚Äûjelent√©sekr≈ël‚Äù
- A laikusok sz√°m√°ra a ‚Äûg√©pi tanul√°s‚Äù misztikusnak t≈±nik. A val√≥s√°gban ez: statisztikai f√ºggv√©nyek optimaliz√°l√°sa nagy adatmennyis√©g f√∂l√∂tt.


**A megfelel≈ë n√©v: Parametric function approximation optimization**
- magyar aj√°nlatok: 
  - *Optimaliz√°l√°ssal el≈ë√°ll√≠tott parametrikus f√ºggv√©ny approxim√°ci√≥*
  - *Optimaliz√°l√°ssal hangolt parametrikus f√ºggv√©nyk√∂zel√≠t√©s*
- ‚Äûparametric‚Äù ‚Üí w, b, W1, W2‚Ä¶ (s√∫lyok)
- ‚Äûfunction‚Äù ‚Üí f(x; Œ∏): A bemenetre (k√©rd√©sre) v√©grehajtjuk a modellben l√©v≈ë f√ºggv√©nyt, ami el≈ë√°lltja a kimenetet (v√°laszt)
- ‚Äûapproximation‚Äù ‚Üí sosem pontos, csak adat-alap√∫ k√∂zel√≠t√©s
- ‚Äûoptimization‚Äù ‚Üí A param√©tereket a modell "tan√≠t√°sa" sor√°n √°ll√≠tottuk be, vagyis optimaliz√°ltuk a tesztadatok seg√≠ts√©g√©vel, hogy megfelel≈ëen v√©gre tudja hajtani a feladat√°t. 




## G√©pi tanul√°s alapk√©plete
A modell√ºnket g√©pi tanul√°s eset√©n ez a k√©plet √≠rja le: 

$$
f_{\theta}(x) \approx y
$$


Az ùëì jel√∂li a modell fel√©p√≠t√©s√©t (t√≠pus√°t), vagyis azt, hogy a bemenetb≈ël hogyan sz√°moljuk ki a kimenetet.

T√≠pusok: 
- Lehet line√°ris f√ºggv√©ny: 
   
   $$ f_{\theta}(x) = w \cdot x + b$$

- Lehet neur√°lis h√°l√≥:

$$
f_{\theta}(x) = \sigma(W_2 \, \sigma(W_1 x + b_1) + b_2)
$$

Ahol: 
- $x$: A bement≈ë param√©ter
- $b$: A pedig a bias, vagyis az eltol√°s (mindj√°rt megl√°tjuk mire kell)

Mi v√°lasztjuk ki, hogy milyen f√ºggv√©nycsal√°dot haszn√°lsz ‚Äî ez maga a modell architekt√∫r√°ja.

A **ùúÉ** a modell tanulhat√≥ param√©terei. A **ùúÉ** minden tanulhat√≥ s√∫lyt √©s bias-t tartalmaz.

- Line√°ris modellben:

$$
\theta = (w, b)
$$


- Neur√°lis h√°l√≥ban:

$$
\theta = \{ W_1, b_1, W_2, b_2, \dots \}
$$


A tanul√°si folyamat pontosan azt jelenti, hogy ezeket a param√©tereket m√≥dos√≠tjuk.


## De mire kell a **bias** (eltol√°s): 

A probl√©ma: Az orig√≥ fogs√°ga. 
K√©pzelj el egy egyszer≈± egyenest, amit a modell√ºnk pr√≥b√°l megtanulni. Ha csak s√∫lyokat (w - weight) haszn√°lunk, az egyenlet √≠gy n√©z ki:

$$y=w‚ãÖx$$



Ebben az esetben, ha a bemenet ($x$) nulla, akkor a kimenet ($y$) is mindig nulla lesz. Ez azt jelenti, hogy az egyenesednek mindenk√©ppen √°t kell haladnia az orig√≥n. Ez hatalmas korl√°toz√°s, mert a val√≥s vil√°g adatai ritk√°n illeszkednek olyan egyenesre, ami a null√°b√≥l indul.

![](docs/image-2025-11-29-19-29-54.png)

**Gyakorlati p√©lda**: H≈ëm√©rs√©klet √°tv√°lt√°s K√©pzeld el, hogy a modellnek meg kell tanulnia √°tv√°ltani a Celsius-t (x) Fahrenheit-be (y). A k√©plet:

$$y=1.8‚ãÖx+32$$

- Itt a $w$ (s√∫ly) az 1.8.
- A $b$ (bias) pedig a 32.

Ha nem lenne $b$ (teh√°t $b=0$ lenne), a modell azt hinn√©, hogy 0¬∞C = 0¬∞F. De tudjuk, hogy ez nem igaz, mert 0¬∞C = 32¬∞F. A bias (32) az a korrekci√≥s sz√°m, ami "helyre teszi" az egyenest a nullapontn√°l.


## Hogyan k√©rdez√ºnk a betan√≠tott modellt√∂l

A m√°r betan√≠tott modellben ahol a param√©terek ($\theta$) m√°r fixek, beadunk egy k√©rd√©st a modellnek: $f_Œ∏‚Äã(x)$, ahol a k√©rd√©st az $x$ szimboliz√°lja, √©s a modell a megtanult param√©terek alapj√°n kisz√°molja a kimenetet. 

Ez azt jelenti:

- beadunk egy bemenetet: $x$
- a modell ($f$) lefut az aktu√°lis param√©terekkel ($Œ∏$),
- √©s el≈ë√°ll√≠t egy becsl√©st:

$$
\hat{y} = f_{\theta}(x)
$$


A modell c√©lja nem az, hogy t√∂k√©letes legyen, hanem hogy a becsl√©s:

- a becs√ºlt √©rt√©k k√∂zel van a val√≥di √©rt√©khez,
- √©s min√©l jobban k√∂zel√≠t, ann√°l jobb a tanul√°s.

> A Machine Learning l√©nyege: param√©tereket √∫gy √°ll√≠tunk be, hogy a modell "j√≥" k√∂zel√≠t√©st adjon. A j√≥ itt azt jelenti, hogy az adott felhaszn√°l√°si c√©l mellett elfogadhat√≥ legyen a v√°lasz pontoss√°ga. 

<br>

---
# A modell tan√≠t√°sa
### Mit nevez√ºnk tan√≠t√°snak

A $w$ √©s a $b$ param√©tereket a model a tan√≠t√°s sor√°n hat√°rozza meg. A tanul√°si f√°zisban ezek folyamatosan v√°ltoznak. Mikor befejezt√ºk a modell tan√≠t√°s√°t, a $w$ √©s $b$ m√°r nem v√°ltozik tov√°bb, ezek a modell saj√°tjai. A modell v√°laszai att√≥l f√ºgg≈ëen lesznek pontosak vagy kev√©ss√© pontosak, hogy mennyire j√≥ f√ºggv√©nyt haszn√°lunk a modellben √©s hogy kapott e kell≈ë sz√°m√∫ tan√≠t√°si p√©ld√°t, hogy j√≥l be√°ll√≠tsa a $w$ √©s a $b$ √©rt√©keket. 


$$ \hat y = w \cdot x + b$$


Miel≈ëtt elkezden√©nk tan√≠tani a modellt, a $w$ √©s $b$ param√©tereknek v√°lasztunk egy v√©letlen √©rt√©ket: 

$$
w \sim \text{random}, \qquad b \sim \text{random}
$$

Vagy ak√°r $0$-ra is √°ll√≠thatjuk ≈ëket. 

Kicsit leegyszer≈±s√≠tve, fogjuk az √∂sszes tan√≠t√≥ adatot, majd sorba kisz√°m√≠tjuk, hogy milyen √©rt√©ket adna a rendszer az aktu√°lis $w$ √©s $b$ √©rt√©kek mellett, ezt jel√∂lj√ºk ($\hat{y}$). Majd megn√©zz√ºk, hogy ez mennyiben t√©r el a v√°rt v√©geredm√©nyt≈ël ($y$), majd ennek f√ºggv√©ny√©ben kisz√°m√≠tjuk, hogy mennyivel kell a $w$ √©s $b$ √©rt√©keket m√≥dos√≠tani, √©s kezdj√ºk el≈ër√∂l a k√ºl√∂nbs√©g (hiba) kisz√°m√≠t√°s√°t az √∂sszes tan√≠t√≥ adaton √∫jra √©s √∫jra, am√≠g nem kapunk egy elfogadhat√≥ v√©geredm√©nyt.

### Epoch √©s Learning rate

A tanul√°si folyamat √∫gynevezett **epoch√°kra** van bontva. Egy epoch√°n bel√ºl az √∂sszes tesztadatra kisz√°moljuk a hib√°t, majd ezeknek az √°tlaga alapj√°n hat√°rozzuk meg, hogy a $w$ √©s $b$ param√©tereket (s√∫lyokat) milyen ir√°nyba kell elmozgatni. 

Ha meghat√°roztuk a gradiens √°ltal mutatott ir√°nyt, akkor egy el≈ëre meghat√°rozott konstans l√©p√©sm√©rettel mozd√≠tjuk el a param√©tereket abba az ir√°nyba, ahol a vesztes√©g cs√∂kken.
Ezt a konstans l√©p√©sm√©retet jel√∂lj√ºk $\eta$-val, amit **learning rate**-nek nevez√ºnk.

Az $\eta$ megv√°laszt√°sa m√©rn√∂ki feladat, √©s igazodnia kell:
- a modell t√≠pus√°hoz,
- az adatok m√©ret√©hez √©s sk√°l√°j√°hoz,
- a vesztes√©gf√ºggv√©ny g√∂rb√ºlet√©hez.

Ha az $\eta$ t√∫l kicsi, akkor:
- a s√∫lyok lassan v√°ltoznak,
- t√∂bb epoch√°ra van sz√ºks√©g,
- extr√©m esetben a tanul√°s szinte meg sem mozdul,

Ha az $\eta$ t√∫l nagy, akkor:
- ugr√°l a modell, folyton nagyobbat korrig√°lunk √©s a hiba oszcill√°l mindig ford√≠tott el≈ëjellel, hol nagyobb hol kisebb mint k√©ne legyen
- nem konverg√°l
- a vesztes√©g csak egyre n≈ë
- sz√©tesik a tanul√°s


### SSE = Sum of Squared Errors meghat√°roz√°sa

Teh√°t minden epoch√°n bel√ºl az √∂sszes tan√≠t√≥ adatra kisz√°m√≠tjuk a hib√°t az aktu√°lis $w$ √©s $b$ param√©terek mellet, majd az √∂sszes hiba √°tlag√°t egy el≈ëre meghat√°rozott k√©plettel kisz√°m√≠tjuk, ezt az √°tlagot nevezz√ºk **gradient descent**-nek. 

Egy megadott tan√≠t√≥ adatp√°r eset√©ben, az $x$ k√©rd√©sre, megn√©zz√ºk, hogy az aktu√°lis s√∫lyok mellett milyen v√°laszt adna a rendszer: ($\hat{y}$)

$$
\hat{y} = w_{actual} x + b_{actual}
$$

Majd kapott v√©geredm√©ny ($\hat{y}$) √©s az elv√°rt v√©geredm√©ny ($y$) k√ºl√∂nbs√©g√©b≈ël kisz√°m√≠tjuk a hib√°t: 

$$
L = (\,\hat{y} - y\,)^2
$$

Azonban mi egy epoch√°n bel√ºl az √∂sszes hiba n√©gyzet√©nek az √°tlag√°t keress√ºk a gradient descent meghat√°roz√°s√°hoz, amit az al√°bbi k√©pet √≠r le: 


$$
L = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2
$$

Ahol: 
- $\hat y_i$: Az i-edik tesztadatra adott v√°lasza a rendszernek az adott $w$ √©s $b$ s√∫lyok mellett.
- $y_i$: Az i-edik teszt k√©rd√©sre elv√°rt v√°lasz. 
- $i$ fut $n$-ig, vagyis az √∂sszes mint√°ra kisz√°m√≠tjuk a hib√°k n√©gyzet√©t √©s azokat √∂sszeadjuk. 
- $\frac 1 n$: Ett≈ël lesz √°tlag, mert elosztjuk a mint√°k/hib√°k sz√°m√°val


### A radienscs√∂kkent√©s kisz√°m√≠t√°sa √°ltal√°noss√°gban



Miden epocha v√©g√©n "gradient descent" (gradienscs√∂kkent√©s) megmondja, hogyan kell m√≥dos√≠tani $w$ √©s $b$ √©rt√©k√©t, hogy a hiba cs√∂kkenjen:

$$
    w \leftarrow w - \eta \frac{\partial L}{\partial w}
$$

$$
b \leftarrow b - \eta \frac{\partial L}{\partial b}
$$


- $\eta$: A learning rate azt szab√°lyozza, hogy a gradient descent mekkora l√©p√©seket tegyen a s√∫lyok friss√≠t√©sekor. Ez egy fix, el≈ëre meghat√°rozott hiperparam√©ter.
- $\frac{\partial L}{\partial w}$: A hiba parci√°lis deriv√°ltja w szerint, vagyis annak a m√©rt√©ke, hogy a vesztes√©g L hogyan v√°ltozik, ha a w s√∫lyt egy picit m√≥dos√≠tjuk. A parci√°lis deriv√°lt ir√°nyt mutat. Ha a w √©rt√©k√©t egy hangy√°nyit n√∂velj√ºk vagy cs√∂kkentj√ºk, akkor a vesztes√©g n√∂vekszik vagy cs√∂kken
  - A parci√°lis deriv√°lt megmondja:
    - merre romlik a modell,
    - merre javul a modell,
    - mennyire meredeken v√°ltozik a hiba a w ir√°ny√°ban.

<br>

A tanul√°s v√©g√©n $w$ √©s $b$ fix √©rt√©kre be√°llnak, √©s ezek egy√ºtt alkotj√°k a modellt, ami √°ltal√°nos√≠t.



Ha a modell param√©tereit √∂sszevonva $\theta$ -val jel√∂lj√ºk, vagyis: 

$$
\theta = [w,b]
$$

Akkor a gradiens cs√∂kkent√©st az al√°bbi k√©pet √≠rja le: 


$$
\theta \leftarrow \theta - \eta \nabla_{\theta} L
$$

Ahol $\nabla_{tehta} L$ a vesztes√©gf√ºggv√©ny parci√°lis deriv√°ltjai az √∂sszes param√©ter szerint. 

Teh√°t a gradiens = egy vektor, amely:
- els≈ë eleme: a vesztes√©g v√°ltoz√°sa w ir√°ny√°ban
- m√°sodik eleme: a vesztes√©g v√°ltoz√°sa b ir√°ny√°ban



<br>

### A gradient descent kisz√°m√≠t√°sa line√°ris regresszi√≥ eset√©n

A Mean Squared Error defin√≠ci√≥ja:

$$
L = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2
$$

√âs mivel:

$$
\hat{y}_i = w x_i + b
$$

ez√©rt:

$$
L = \frac{1}{n}
\sum_{i=1}^{n} (w x_i + b - y_i)^2
$$


A deriv√°lt w-re:

$$
\frac{\partial L}{\partial w}
=
\frac{\partial}{\partial w}
\left[
\frac{1}{n}
\sum_{i=1}^{n}
(w x_i + b - y_i)^2
\right]
$$

A n√©gyzet deriv√°ltja:

$$
2 (w x_i + b - y_i)\cdot x_i
$$

√çgy:

$$
\frac{\partial L}{\partial w}
=
\frac{2}{n}
\sum_{i=1}^{n}
x_i(\hat{y}_i - y_i)
$$


Ebb≈ël k√∂vetkezik, hogy $w$-re a gradienscs√∂kkent√©s:


$$
w \leftarrow w - \eta \left( \frac{2}{n} \sum_{i=1}^{n} x_i (\hat{y}_i - y_i) \right)
$$

√âs $b$-re ezt ugyan √≠gy k√©ne kisz√°molni. 




**P√©lda:**


Adatok: 
- $w = 0.1$
- $\frac{\partial L}{\partial w} = 5$ -> Tegy√ºk fel, hogy ezt valaki kisz√°molta nek√ºnk, teh√°t nem kell most deriv√°lni. 
- $\eta = 0.01$ -> k√≠s√©rleti √∫ton, el≈ëre meghat√°roztuk

A friss√≠t√©si szab√°ly: 
$$
w \leftarrow w - \eta \frac{\partial L}{\partial w}
$$

Behelyettes√≠tve: 
- $w \leftarrow 0.1 - 0.01 \cdot 5$
- $w \leftarrow 0.1 - 0.05 = 0.05$

<br>

**Magyar√°zat**: A s√∫ly cs√∂kkent, mert a gradiens pozit√≠v volt

$$
\frac{\partial L}{\partial w} > 0
$$

ez√©rt a hiba (‚Äûlejt≈ë‚Äù) felfel√© mutatott √©s a **gradient descent** ellenkez≈ë ir√°nyba l√©p, hogy cs√∂kkentse a vesztes√©get.

<br>

---
# Vektorok √©s m√°trixok

Val√≥s ML-ben az $x$ √©s $y$ jellemz≈ëen vektorok √©s a $w$ √©s $b$ pedig m√°trixok. 

A legegyszer≈±bb p√©lda (mint a lak√°s√°r ‚Üí 1 bemenet ‚Üí 1 kimenet) ritka.

A t√∂bb dimenzi√≥s vektorokkal nagyon sok param√©ter√©t √≠rhatjuk le bemenetnek illetve a kimenetenk. 

Pl. egy h√°z jellemz≈ëi, aminek az √°r√°t szeretn√©k meghat√°rozni egy ML modell seg√≠ts√©g√©vel lehetnek: 
- alapter√ºlet
- szob√°k sz√°ma
- ingatlan kora
- lok√°ci√≥ k√≥d
- f≈±t√©s t√≠pusa
- energiaoszt√°ly

Teh√°t:

$$
x \in \mathbb{R}^n
$$


$$
\hat{y} = W x + b
$$


Akkor:

$$
W \in \mathbb{R}^{m \times n}
$$
$$
b \in \mathbb{R}^m
$$
$$
x \in \mathbb{R}^n
$$
$$
\hat{y} \in \mathbb{R}^m
$$


- $n$ = bemenet dimenzi√≥ja
- $m$ = kimenet dimenzi√≥ja

Ami nem m√°s, mint  egy line√°ris neuron r√©teg (dense layer) matematikai le√≠r√°sa.


**P√©lda:**

Tegy√ºk fel:

- $n=6$, vagyis a bemeneti k√©rd√©st 6 dimenzi√≥val reprezent√°ljuk, pl 6 param√©terrel √≠runk le egy lak√°st, 
- $m=3$, √©s arra tan√≠tjuk meg a modellt, hogy megmondja az √°r√°t, azt hogy mennyi id≈ë alatt lehet eladni, √©s hogy mennyire tartja az √°r√°t, vagyis 3 param√©tert v√°runk vissza a modellt≈ël. 

Akkor:

$$
x =
\begin{bmatrix}
x_1 \\
x_2 \\
x_3 \\
x_4 \\
x_5 \\
x_6
\end{bmatrix}
$$

$$
W =
\begin{bmatrix}
w_{11} & w_{12} & \dots & w_{16} \\
w_{21} & w_{22} & \dots & w_{26} \\
w_{31} & w_{32} & \dots & w_{36}
\end{bmatrix}
$$

$$
b =
\begin{bmatrix}
b_1 \\
b_2 \\
b_3
\end{bmatrix}
$$


A line√°ris transzform√°ci√≥:

$$
\hat{y} = W x + b
$$


<br>

---
# P√©lda programok

## Egy egydimenzi√≥s bemenet √©s kimenet

Egy olyan modellt szeretn√©nk k√©sz√≠teni, ami meg tudja mondani egy lak√°s √°r√°t a megadott n√©gyzetm√©ter alapj√°n an√©lk√ºl, hogy explicit megmondan√°nk a programunknak, hogy a n√©gyzetm√©terb≈ël hogyan kell kisz√°molni a lak√°s √°r√°t. 


<br>

A tan√≠t√≥ adatok az al√°bbiak lesznek (enn√©l sokkal t√∂bb adattal): 


| Index | Alapter√ºlet (sizes) | √År (prices) |
|-------|----------------------|-------------|
| 0     | 35 m¬≤               | 30 M Ft     |
| 1     | 40 m¬≤               | 33 M Ft     |
| 2     | 42 m¬≤               | 34 M Ft     |
| 3     | 45 m¬≤               | 36 M Ft     |
...


Ezek alkotnak adatp√°rokat, vagyis tan√≠t√≥ p√©ld√°kat: 
$(x_i, y_i)$


![](docs/image-2025-11-30-19-03-52.png)


## 